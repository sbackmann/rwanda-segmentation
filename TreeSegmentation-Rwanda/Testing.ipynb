{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dc7b7a0-2422-45a8-9dc9-708f0ed66506",
   "metadata": {},
   "source": [
    "# Testing\n",
    "This notebook is for visualizing and evaluating the model results from the different experiments that were evaluated in the thesis.\n",
    "1. The dataset is created. If not already happened, the images are split into train, validation and test set and divided into smaller image patches. The JSON files that transform the data into COCO format are generated.\n",
    "2. By specifying the experiment, for which the results shall be inspected, the respective trained model weights are downloaded and the configuration for the experiment is set.\n",
    "3. Different options for visualizing the inference results are presented.\n",
    "4. The model can be evaluated on one of the subsets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31990a28-d08d-463b-87eb-cd5c3735a9c6",
   "metadata": {},
   "source": [
    "## 0: Check Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdb650d-b658-4ad0-b7f1-1050f2c4a692",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import mmcv\n",
    "\n",
    "ROOT_DIR = os.path.abspath(\"../MMDetection\")\n",
    "sys.path.append(ROOT_DIR)\n",
    "\n",
    "# Check Pytorch installation\n",
    "import torch, torchvision\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "\n",
    "# Check MMDetection installation\n",
    "import mmdet\n",
    "print(mmdet.__version__) # should be 2.25.0\n",
    "\n",
    "# Check mmcv installation\n",
    "from mmcv.ops import get_compiling_cuda_version\n",
    "print(get_compiling_cuda_version()) # should be matching Pytorch's cuda version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2180488-faad-4697-a2ea-68888a86c122",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1: Create Dataset\n",
    "\n",
    "If the following values (except for the paths) are left unchanged, image patches and JSON files are created so that all experiments barring the one that uses image patches with a minimum scale of 150 pixels (modification \\[b\\]) can easily be reproduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d444f9a-8dc0-420f-8db0-93d527ffbcd3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from DataInitialization import DataInitialization\n",
    "\n",
    "# Path to the folder containing the original satellite images\n",
    "INPUT_IMG_DIR = os.path.abspath(\"./data/Training_Images_RGB\")\n",
    "# Path to the folder containing the `.shp` annotations\n",
    "ANNO_DIR = os.path.abspath(\"./data/Training_tree_polygons\")\n",
    "# Folder where train, val and test sets are created\n",
    "IMG_DIR = os.path.dirname(INPUT_IMG_DIR)\n",
    "\n",
    "# If sets are not created randomly, these indices mark the images belonging to the validation set\n",
    "# and test set\n",
    "val_images = [3, 8, 15, 16, 20, 28, 33, 35, 40, 43, 52, 60, 65, 68, 78, 79, 83, 89, 95, 98, 100, 107]\n",
    "# For the reproduction of the reduced test set, the images 45, 91 and 99 need to be removed.\n",
    "test_images = [5, 7, 17, 18, 24, 30, 41, 45, 47, 49, 51, 59, 62, 70, 76, 77, 81, 91, 99, 104, 105, 108]\n",
    "\n",
    "# Width and height of the image patches. If a list is passed, patches of multiple sizes are created for\n",
    "# the training set. For the validation and test set, only image patches of the first size are created. \n",
    "min_width = [300, 600]\n",
    "min_height = [300, 600]\n",
    "# Which subsets to create. \n",
    "subsets = ['train', 'val', 'test']\n",
    "\n",
    "# Set up initialization of the datasets. If ``force`` is False, for each subset image patches and JSON\n",
    "# files are only created if they do not exist thus far. If set to true, additional image patches are\n",
    "# created and JSON files are regenerated, including all image patches.\n",
    "ri = DataInitialization(img_dir=INPUT_IMG_DIR,\n",
    "                          img_output_dir=IMG_DIR,\n",
    "                          subsets=subsets,\n",
    "                          force=False)\n",
    "\n",
    "# Method to create image patches\n",
    "ri.split_crop(min_width=min_width, min_height=min_height, random_split=False, val_images=val_images, test_images=test_images)\n",
    "# Method to create JSON files in COCO format\n",
    "ri.load_rwanda_data(anno_dir=ANNO_DIR)\n",
    "ri.load_rwanda_data(anno_dir=ANNO_DIR, load_prefix=\"300\", subsets=['train'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee98ff0-1c12-44c3-82b1-e6150d2cdfcf",
   "metadata": {},
   "source": [
    "## 2: Load Experiment for Testing\n",
    "To reproduce the results of the different models evaluated in the thesis, their configurations and weights can be loaded by specifying the experiment name. A list of all the experiment_names can be generated with ``print_experiments()``.\n",
    "\n",
    "I noticed that sometimes the weight downloads within JupyterLab from Github are very slow. Alternatively to the automatic download in JupyterLab, they can be downloaded manually from https://github.com/sbackmann/rwanda-instance/releases/tag/v2.25.0 and then need to be placed in their respective experiment directories (e.g. ./experiments/00_MaskR50_-/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c520ed5d-8a35-4459-aeb7-019847605a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ModelInitialization import ModelInitialization\n",
    "\n",
    "ModelInitialization.print_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaad9be3-459b-46e0-b0fd-67d4f6f443b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ModelInitialization import ModelInitialization\n",
    "\n",
    "# Specify which model shall be tested.\n",
    "experiment = \"MaskR50_acd\"\n",
    "\n",
    "mi = ModelInitialization(experiment=experiment)\n",
    "model_dir = \"./pretrained_models\"\n",
    "\n",
    "# Downloads the trained weights if not already downloaded\n",
    "checkpoint = mi.load_experiment_weights()\n",
    "# Loads configuration for chosen experiment\n",
    "cfg = mi.load_config(anno_dir=ANNO_DIR, img_dir=IMG_DIR, checkpoint=checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5694eca2-ef9c-4b78-b017-6292f0a29fad",
   "metadata": {},
   "source": [
    "## 3: Visualize Inference Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b9a877-7f07-4890-a155-92503279af85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from RwandaVisualization import RwandaVisualization\n",
    "\n",
    "v = RwandaVisualization(cfg, checkpoint, subset='val')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c02a2fc-d193-4732-b5f1-0d865731dec6",
   "metadata": {},
   "source": [
    "### 3.1: Compare Inference Results to the Ground Truth\n",
    "Plots the ground truth image patch next to the model's prediction. If no file name is specified, a random image from the subset is selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3666e455-6d36-4f51-9b2d-19410ce579a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Either set img to None (random image) or specify image name (this must be in the subset)\n",
    "img = None  # \"300x300_image_65_1CNW1R.tif_tile_0-0.tif\"\n",
    "v.eval_image(img=img, save_fig=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141a75ea-d0c7-4b23-9ba0-0069137f9d6c",
   "metadata": {},
   "source": [
    "### 3.2: Batch Ground Truth and Inference Generation\n",
    "For a large scale comparison of ground truth and inference results, all ground truth annotations and predictions can be saved into a directory for further inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d8e5c2-e11f-4cf2-bbe7-c58dec99270c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify directory (does not have to be existent) to store ground truth images. Ground truths are only created if the specified directory is empty.\n",
    "ground_truth_dir = \"./visualization/ground_truths\"\n",
    "v.save_ground_truths(out_dir=ground_truth_dir)\n",
    "\n",
    "# Specify directory (does not have to be existent) to store inference results. Results are only created if the specified directory is empty.\n",
    "inference_dir = f\"./visualization/{experiment}_inference\"\n",
    "v.save_inference_results(out_dir=inference_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eed8f90-a882-4c17-8079-72780847ea30",
   "metadata": {},
   "source": [
    "### 3.3: Show the Inference Results only\n",
    "Alternatively, the full path to the image that should be inferenced can be specified. Then, only the prediction will be shown. This might be useful to test the model on new data that is neither in the train, val or test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6576c74-0f5c-4b86-bf6a-b4c7e7f514a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, the full path to the image must be specified.\n",
    "img = os.path.join(IMG_DIR, \"val/300x300_image_65_1CNW1R.tif_tile_0-0.tif\")\n",
    "v.plot_inference_results(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e60f81f-140e-4a4c-ae10-230ffc2935d1",
   "metadata": {},
   "source": [
    "## 4: Evaluate Model Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e067e9b1-f939-4516-a41c-a31026162045",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ModelEvaluation import evaluate_rwanda\n",
    "# Specify out_file if the results are to be saved.\n",
    "out_dir = './visualization'\n",
    "evaluate_rwanda(cfg, checkpoint, subset=\"test\", out_dir=out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449464af-8246-4991-b7b2-ef4b2e9d96d4",
   "metadata": {},
   "source": [
    "The model metrics as well as their training losses can also be inspected by looking at their tensorboard log files and thus without having to reproduce the reuslts. For this, tensorboard has to be opened with ``./experiments`` as the log directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648f8975-8d41-4db6-8660-fee28ecf0285",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554055f2-6d64-4f48-b56e-6722a69bf796",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard --logdir=./experiments"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
